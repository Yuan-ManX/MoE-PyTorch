# MoE-PyTorch
PyTorch implementation of Sparsely-Gated Mixture-of-Experts (MoE).
